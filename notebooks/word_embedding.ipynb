{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add the root directory of the project to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Import the BERT embedding functions\n",
    "from data_preprocessing.word_embedding import apply_bert_embeddings, convert_embeddings_to_numpy\n",
    "from data_preprocessing.text_cleaning import clean_text\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"preprocessed_data.csv\")  # Replace with your actual dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       booked online about months before my trip was ...\n",
       "1       just missed some information on pier need foun...\n",
       "2                                    all went well thanks\n",
       "3       the big one is much better than the small one ...\n",
       "4       there is just one negative point the office st...\n",
       "                              ...                        \n",
       "9430    the awful event left me feeling frustrated bad...\n",
       "9431    had an absolutely amazing time everything was ...\n",
       "9432    the dreadful event left me feeling frustrated ...\n",
       "9433                      it was okay nothing too special\n",
       "9434    had an absolutely amazing time everything was ...\n",
       "Name: cleaned_review, Length: 9435, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_review']= df['Review'].apply(clean_text)\n",
    "df['cleaned_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data_preprocessing.word_embedding import apply_bert_embeddings, convert_embeddings_to_numpy\n",
    "from data_annotation.pseudo_labeling import apply_pseudo_labels\n",
    "from sentiment_model.train_model import train_classifier\n",
    "from sentiment_model.active_learning import select_uncertain_samples\n",
    "\n",
    "\n",
    "# Step 1: Apply BERT embeddings\n",
    "df = apply_bert_embeddings(df, column_name=\"cleaned_review\")\n",
    "X = convert_embeddings_to_numpy(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_annotation.pseudo_labeling import apply_pseudo_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data_annotation.pseudo_labeling  # Ensure the module is imported\n",
    "import sentiment_model.train_model\n",
    "import sentiment_model.active_learning\n",
    "importlib.reload(sentiment_model.active_learning)\n",
    "importlib.reload(data_annotation.pseudo_labeling)\n",
    "from data_annotation.pseudo_labeling  import apply_pseudo_labels\n",
    "from sentiment_model.train_model import train_classifier\n",
    "from sentiment_model.active_learning import select_uncertain_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 971\n",
      "Unlabeled Data Size: 8464\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Generate pseudo-labels with confidence filtering\n",
    "df_train, df_unlabeled = apply_pseudo_labels(df, column_name=\"cleaned_review\", threshold=0.85)\n",
    "\n",
    "# Check size of train and unlabeled data\n",
    "print(\"Training Data Size:\", len(df_train))\n",
    "print(\"Unlabeled Data Size:\", len(df_unlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m train_classifier(df_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Apply Active Learning\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m uncertain_samples \u001b[38;5;241m=\u001b[39m \u001b[43mselect_uncertain_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_unlabeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save for manual labeling\u001b[39;00m\n\u001b[0;32m     10\u001b[0m uncertain_samples\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebooks/uncertain_samples.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\sentiment_analysis\\sentiment_model\\active_learning.py:9\u001b[0m, in \u001b[0;36mselect_uncertain_samples\u001b[1;34m(df_unlabeled, model, column_name, top_n)\u001b[0m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[0;32m     11\u001b[0m texts \u001b[38;5;241m=\u001b[39m df_unlabeled[column_name]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     12\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "from sentiment_model.train_model import train_classifier\n",
    "from sentiment_model.active_learning import select_uncertain_samples\n",
    "# Train BERT Classifier\n",
    "model, *_ = train_classifier(df_train)\n",
    "\n",
    "# Apply Active Learning\n",
    "uncertain_samples = select_uncertain_samples(df_unlabeled, model, top_n=500)\n",
    "\n",
    "# Save for manual labeling\n",
    "uncertain_samples.to_csv(\"notebooks/uncertain_samples.csv\", index=False)\n",
    "\n",
    "print(\"Uncertain samples saved for manual annotation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
